Epoch 1/6:   0%|                                                                                                                                               | 0/201 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/rubenjh2/Desktop/mp-release-sp25/src/mp1/train.py", line 216, in <module>
    train()
  File "/home/rubenjh2/Desktop/mp-release-sp25/src/mp1/train.py", line 132, in train
    binary_logits, instance_embeddings = enet_model(images)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rubenjh2/Desktop/mp-release-sp25/src/mp1/models/enet.py", line 451, in forward
    x_binary = self.regular_binary_5_1(x_binary)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rubenjh2/Desktop/mp-release-sp25/src/mp1/models/enet.py", line 145, in forward
    ext = self.ext_conv3(ext)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 4.93 GiB total capacity; 3.82 GiB already allocated; 68.62 MiB free; 3.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
