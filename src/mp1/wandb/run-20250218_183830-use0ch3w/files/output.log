Epoch 1/10:   0%|                                                                                                                                               | 0/51 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/rubenjh2/Desktop/mp-release-sp25/src/mp1/train.py", line 211, in <module>
    train()
  File "/home/rubenjh2/Desktop/mp-release-sp25/src/mp1/train.py", line 127, in train
    binary_logits, instance_embeddings = enet_model(images)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rubenjh2/Desktop/mp-release-sp25/src/mp1/models/enet.py", line 412, in forward
    x = self.regular1_4(x)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rubenjh2/Desktop/mp-release-sp25/src/mp1/models/enet.py", line 151, in forward
    return self.out_activation(out)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rubenjh2/.conda/envs/tusimple/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 1309, in forward
    return F.prelu(input, self.weight)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 4.93 GiB total capacity; 3.84 GiB already allocated; 68.25 MiB free; 3.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
